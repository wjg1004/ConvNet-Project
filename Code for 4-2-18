import sys
sys.path.append('c:\\users\\berg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages')

from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.optimizers import SGD,RMSprop,adam
from keras.utils import np_utils

import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import os
import tensorflow
from PIL import Image
from numpy import *
from scipy.misc import imread

from sklearn.utils import shuffle
from sklearn.cross_validation import train_test_split

import skimage
from skimage import io
import os



##### resize and put all images into one file and create a 1-dimensional array for the corresponding labels #####

labels = []
for i in range(0,120):
        labels.append(0)
for i in range(0,108):
        labels.append(1)

new_folder = 'C:\\Users\\Berg\\Desktop\\all_leaves' 
all_leaves_path = 'C:\\Users\\Berg\\Desktop\\lab'
list_leaves = os.listdir(all_leaves_path)
num_leaf_types = size(list_leaves)
labels = []
count=-1

for leaf_folder in list_leaves:
    count = count+1
    temp_list = os.listdir(all_leaves_path + '\\' + leaf_folder)
    for i in range(0,size(temp_list)):
        labels.append(count)
    for leaf_image in temp_list:
        im = Image.open(all_leaves_path + '\\' + leaf_folder + '\\' + leaf_image)
        img = im.resize((64,64))
        img.save(new_folder + '\\' + leaf_image, "JPEG")


##### flatten the images and fit all of them into one array #####

imlist = os.listdir(new_folder)
immatrix = array([((imread(new_folder + '\\' + imlist[0]))).flatten()])
shape(immatrix)
del imlist[0]
for image in imlist:
        immatrix = vstack((immatrix,array([(imread(new_folder + '\\' + image)).flatten()])))


##### shuffle #####
        
data,Label = shuffle(immatrix, labels, random_state=2)
train_data = [data,Label]


##### split data into testing and training sets #####

img_rows, img_cols = 64, 64

(X, y) = (train_data[0],train_data[1])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)

X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

X_train /= 255
X_test /= 255

print('X_train shape:', X_train.shape)
print(X_train.shape[0], 'train samples')
print(X_test.shape[0], 'test samples')


###### create the label matrix where each row is binary for a given leaf ######
nb_classes = 185 

Y_train = np_utils.to_categorical(y_train, nb_classes)
Y_test = np_utils.to_categorical(y_test, nb_classes)

i = 100
plt.imshow(X_train[i, 0], interpolation='nearest')
print("label : ", Y_train[i,:])


################

#batch_size to train
batch_size = 32
# number of epochs to train
nb_epoch = 20


# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
nb_pool = 2
# convolution kernel size
nb_conv = 3


############ make the model #####################

model = Sequential()

model.add(Convolution2D(nb_filters, kernel_size=(nb_conv),
                        input_shape=(img_rows, img_cols, 1),
                        padding='same'))
convout1 = Activation('relu')
model.add(convout1)
model.add(Convolution2D(nb_filters, nb_conv, nb_conv))
convout2 = Activation('relu')
model.add(convout2)
model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(nb_classes))
model.add(Activation('softmax'))
model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=["accuracy"])


hist=model.fit(X_train,Y_train,batch_size=batch_size,epochs=nb_epoch,verbose=1, validation_split=0.2)

